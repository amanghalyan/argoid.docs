[argoid:children]
docker_parent
docker
zookeeper
redis
ssh_gateway
hdfs
yarn
nifi
prometheus
#alert_manager
hive
mysql
#airflow
alertmanager
grafana
presto
cassandra
kairosdb
docker
node_exporter
zeppelin
redis_server

[argoid:vars]

ssh_users=[ "arul", "bala", "manjunath",  "vasu", "chackra", "jeyaraj", "kurian", "mangai" ]
delete_ssh_users=[]
#create_ssh_private_keys=False
enable_superuser_privileges=True
ssh_superusers=["chackra", "jeyaraj","bala", "mangai", "manjunath","vasu"]
selinux_state=disabled
list_disks_shell_command=" fdisk -l 2>/dev/null |awk '/^Disk \//{print substr($2,0,length($2)-1)}' | awk '!/sda/' | awk '!/sdb/' | sort "
disk_type=sdc
disk_mount_folder=/data/1
fs_file_max=262144
nofile_limit=262144
common_utilities=["epel-release", "lsof", "wget"]
argoid_nexus_ip=10.0.0.29
argoid_bigtop_ip=52.156.121.90
bigtop_url=http://{{argoid_bigtop_ip}}/repos
repo_name="argoid.repo"
jdk_download_url=http://{{argoid_bigtop_ip}}/argoid_repo/java/jdk-8u201-linux-x64.rpm
argoid_nexus_port=8081
argoid_bigtop_repo_url=http://{{argoid_bigtop_ip}}/repos
argoid_repository_hostname=argoid-demo-gw-1
argoid_nexus_repo_url=http://{{argoid_nexus_ip}}:{{argoid_nexus_port}}/repository/argoid-rpm-repos/rhel/x86-64/
java_home_path=/usr/java/latest/
jmx_exporter_prometheus_download_url=http://{{argoid_bigtop_ip}}/argoid_repo/jmx_prometheus_javaagent-0.3.0.jar
jmx_exporter_dir=/opt/jmx_exporter
jmx_exporter_config_file={{jmx_exporter_dir}}/config.yml
jmx_exporter_java_agent_file={{jmx_exporter_dir}}/jmx_prometheus_javaagent-0.3.0.jar
#alert_manager_port=9093 #To be moved to alert_manager defaults once alert_manager role is created


[ssh_gateway]
192.0.1.4

[ssh_gateway:vars]
create_ssh_private_keys=True
enable_superuser_privileges=True
ssh_superusers=["chackra", "jeyaraj"]


[docker_parent:children]
docker
airflow
postgres
grafana
prometheus
prometheus_node
alertmanager
nginx
redash

[docker_parent:vars]
docker_edition='ce'
docker_package="docker-{{ docker_edition }}"
docker_package_state=present
docker_yum_repo_url=https://download.docker.com/linux/{{ (ansible_distribution == "Fedora") | ternary("fedora","centos") }}/docker-{{ docker_edition }}.repo
docker_yum_gpg_key=https://download.docker.com/linux/centos/gpg
docker_compose_version="1.23.2"
docker_venv_path=/opt/docker_venv
docker_installation_python_path=/usr/bin/python
docker_python_interpreter={{ docker_venv_path }}/bin/python

[docker]
172.31.252.14
172.31.252.13


[airflow]
172.31.252.13


[airflow:vars]
airflow_webserver_port=8082
airflow_enable_statsd_monitoring=True
airflow_dir=/home/airflow/airflow
airflow_user=airflow
airflow_dags_dir= /opt/airflow/dags
airflow_executor=SequentialExecutor
plugins_folder=/home/airflow/airflow/plugins
dag_processor_manager_log_location=/home/airflow/airflow/logs/dag_processor_manager/dag_processor_manager.log
child_process_log_directory=/home/airflow/airflow/logs/scheduler
base_log_folder=/home/airflow/airflow/logs
python3_virtualenv_path=/opt/python3_venv
python_bin_path=/opt/python3_venv/bin/python
python_bin_path_airflow=/opt/python3_venv/bin/airflow
##airflow postgres database user and password creation
airflow_packages=[ "SQLAlchemy==1.3.20","apache-airflow[postgres]==2.0.1", "apache-airflow[statsd]", "apache-airflow[cncf.kubernetes]", "wtforms==2.3.3"]
airflow_postgres_db=airflow
airflow_postgres_user=airflow
airflow_postgres_password=airflow
###statsd_monitoring paths
statsd_exporter_port=9102
statsd_exporter_docker_image=prom/statsd-exporter
statsd_exporter_container_name=airflow-statsd-exporter
airflow_statsd_port=9125
###airflow new web user creation(admin role)
airflow_web_user_id=admin
airflow_web_user_first_name=argoid
airflow_web_user_last_name=admin
airflow_web_user_password=argoid
airflow_web_user_role=Admin
airflow_web_user_email=argoid@argoid.com
###logrotation airflow_logs
cron_log_rotation_minutes_utc=30
cron_log_rotation_hour_utc=05
log_to_zip_no_of_days=3
zip_to_delete_no_of_days=7
###systemd script inairflow
environmentfile=/etc/sysconfig/airflow
###spark-monitoring
graphite_exporter_docker_image='prom/graphite-exporter'
graphite_exporter_container_name='spark-graphite-exporter'
graphite_exporter_port=9108
graphite_exporter_sink_port=9109
graphite_mapping_dir='/opt/graphite-exporter/'
graphite_mapping_conf='{{graphite_mapping_dir}}/graphite_mapping.conf'
spark_dir=/opt/spark




[grafana]
172.31.252.13

[grafana:vars]
grafana_mount_data_dir=/data/1/grafana_data
grafana_data_dir=/var/lib/grafana
grafana_port=3000
grafana_container_name=grafana
grafana_docker_image=grafana/grafana:6.7.1



[prometheus]
172.31.252.13

[prometheus:vars]
prometheus_project=prod_saas
prometheus_mount_config_dir=/opt/prometheus
prometheus_config_dir=/etc/prometheus
prometheus_port=9090
prometheus_container_name=prometheus
prometheus_docker_image=prom/prometheus:v2.22.1
node_exporter_port=9100
node_exporter_container_name=node_exporter
node_exporter_docker_image=prom/node-exporter:latest
prometheus_mount_data_dir=/data/1/prometheus
prometheus_data_dir=/prometheus


[prometheus_node]
10.0.0.40 prometheus_job_custom_config="{\"metrics_path\":\"/prometheus\",\"metric_relabel_configs\":[{\"action\":\"replace\",\"source_labels\":\"[exported_job]\",\"target_label\":\"jenkins_job\"},{\"action\":\"labeldrop\",\"regex\":\"exported_job\"}]}" # Temporary entry

[prometheus_node:vars]
prometheus_job_name_prefix = node_
prometheus_scrape_port = 9200


[alertmanager]
172.31.252.13


[alertmanager:vars]
alertmanager_port=9093
alertmanager_mount_data_dir=/opt/alertmanager
alertmanager_container_name=alertmanager
alertmanager_docker_image=prom/alertmanager:v0.21.0
alertmanager_src_vol="{{alertmanager_mount_data_dir}}/alertmanager.yml"
alertmanager_dest_vol=/alertmanager/alertmanager.yml
alertmanager_receiver_mail="alerts-saas-stage1@argoid.com"
alert_recievers="alerts-saas-stage1"
smtp_auth_username="devops-user1@argoid.com"
smtp_auth_password="DevOps@2020"
smtp_smarthost='smtp.gmail.com:587'
group_wait="45s"
group_interval="20m"
repeat_interval="20m"



[nginx]
172.31.252.14

[nginx:vars]
nginx_port=8000
nginx_exporter_port=9113
nginx_exporter_container_name=nginx-exporter
nginx_exporter_docker_image="nginx/nginx-prometheus-exporter:0.9.0"


[redash]
172.31.252.14

[redash:vars]
redash_http_port=80
redash_docker_image_tag=8.0.0.b32245
redash_redis_docker_image_tag=5.0-alpine
redash_postgres_docker_image_tag=9.6-alpine
redash_redis_url=redis://redis:6379/0
redash_postgres_password=GjeRkVWyQiGOg0cRdxeXyqspdwEIH2MQ
redash_cookie_secret=VshrV6NyLaBPByFJKPK1knBx4S7jhg1D
redash_secret_key=Oz35dHzmRV7bRqaiLWrBR9Lxi3wDlHUU
redash_database_url=postgresql://postgres:{{ redash_postgres_password }}@postgres/postgres
cadvisor_docker_image=google/cadvisor:latest
cadvisor_container_name=redash_cadvisor
cadvisor_port=8089
redash_admin_username=redash
redash_admin_mail=redash@argoid.com
redash_admin_password=ArGoId
redash_organization_name=argoid

redashdb_backup=False
ssl_enabling=False

redash_container=redash-stage-backups
azure_backup=/opt/redash_backup_scripts/redash_backup/
#redash_secret_key=REDASH_SECRET_KEY
az_storage_key=UilImJy48TPIgdwOCWXQAi9ovSEJCg5lqzJw24ZBra4VFYgOeo458HB+OdkLy43w0I9LEhD2PwlwpoOVovoRiA==
az_auth_mode=key
az_storage_account=argoidinfrabackups
az_storage_string=DefaultEndpointsProtocol=https;AccountName=argoidinfrabackups;AccountKey=UilImJy48TPIgdwOCWXQAi9ovSEJCg5lqzJw24ZBra4VFYgOeo458HB+OdkLy43w0I9LEhD2PwlwpoOVovoRiA==;EndpointSuffix=core.windows.net
nginx_port=443
redash_domain_name=ansible.redash.argoid.com
ssl_certificate=/etc/letsencrypt/live/{{ redash_domain_name }}/fullchain.pem
ssl_certificate_key=/etc/letsencrypt/live/{{ redash_domain_name }}/privkey.pem
ssl_trusted_certificate=/etc/letsencrypt/live/{{ redash_domain_name }}/chain.pem




[python3_venv]
192.0.1.12

[python3_venv:vars]
python_venv_version=3.6
python3_virtualenv_path=/opt/python3_6-virtual_envs/airflow_env


[zookeeper]
172.31.252.13

[zookeeper:vars]
jmx_prometheus_zookeeper_port=10801
zookeeper_initial_memory_allocation=256m
zookeeper_maximum_memory_allocation=256m
zookeeper_max_client_cnxns=60
zookeeper_leader_port=2888
zookeeper_election_port=3888
zookeeper_max_backup_logs=10
zookeeper_log_threshold=DEBUG
zookeeper_port=2181
zookeeper_client_port=2181
zookeeper_ticktime=3000
zookeeper_init_limit=10
zookeeper_sync_limit=5
zookeeper_data_dir=/var/lib/zookeeper

[redis:children]
redis_server
redis_sentinel

[redis_server]
172.31.252.13
172.31.252.14

[redis_sentinel]
172.31.252.13

[redis:vars]
redis_master_enabled={{ groups.redis_server | count > 1}}
redis_sentinel_enabled=False
redis_port=6379
redis_master_ip={{hostvars[inventory_hostname].groups['redis_server'][0]}}
redis_master_enabled={{ groups.redis_server | count > 1}}
#redis_master_enabled=False
redis_source_url=http://download.redis.io/releases/redis-6.2.0.tar.gz
redis_sentinel_port=16379
redis_version=redis-6.2.0
force=yes
redis_password=123
redis_master_password=123
redis_dir= /usr/local/src/redis
redis_db_dir=/var/lib/redis
redis_log_file=/var/log/redis/redis.log
sentinel_log_file=/var/log/redis/redis-sentinel.log
redis_exporter_docker_image=oliver006/redis_exporter
redis_exporter_container_name=redis-exporter
redis_exporter_port=9121
redis_data_source_name=redis://{{ansible_default_ipv4.address}}:{{redis_port}}
redis_replica_parallel_syncs=2

[hadoop_cluster:children]
yarn
hdfs

[hadoop_cluster:vars]
hdfs_bootstrap=True
# hdfs_cluster_name - hdfs-nameservice name
hdfs_cluster_name="argoid-infra-hdfs-testing"
# hdfs_fs_trash_interval - trash retention time in minutes
hdfs_fs_trash_interval=4320
hdfs_dfs_replication=1
hdfs_permission_enabled=true
hdfs_dfs_datanode_du_reserved=1073741824
hdfs_dfs_journalnode_edits_dir=/data/1/dfs/jn
hdfs_namenode_dir=/data/1/dfs/nn
hdfs_datanode_dir_list=['/data/1/dfs/data']
hadoop_log_maxfilesize="256MB"
hadoop_log_maxbackupindex=20
hadoop_security_logger="INFO,RFAS"
hadoop_audit_logger="INFO,RFAAUDIT"
hdfs_audit_rotate_days=90
hdfs_java_home=/usr/java/jdk1.8.0_201-amd64/
hdfs_namenode_heap_size="1024m"
hdfs_namenode_javaOpts="-Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=33701 -javaagent:{{jmx_exporter_java_agent_file}}=33301:{{jmx_exporter_config_file}} "
hdfs_datanode_javaOpts="-Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=33601 -javaagent:{{jmx_exporter_java_agent_file}}=33303:{{jmx_exporter_config_file}}"

hdfs_namenodes={{ groups.hdfs_namenode }}
hdfs_ha_enabled={{ groups.hdfs_namenode | count > 1}}
hdfs_nameservices={{ hdfs_cluster_name }}
hdfs_default_fs="hdfs://{{ hdfs_nameservices if hdfs_ha_enabled else hdfs_namenode[0] + ':8020' }}"
jobhistoryserver_enabled={{ groups.history_jobhistoryserver | count > 0}}
jobhistoryserver_address={{hostvars[inventory_hostname].groups['history_jobhistoryserver'][0]}}:10020
jobhistoryserver_webapp_address={{hostvars[inventory_hostname].groups['history_jobhistoryserver'][0]}}:19888

yarn_enable_log_aggregation=True
yarn_nodemanager_local_dirs_path=['/data/1/tmp/yarn/local']
yarn_nodemanager_log_dirs_path=/data/1/hadoop-yarn/containers
jobhistory_ipc_port=10020
yarn_timeline_web_port=8188
jobhistory_web_port=19888
yarn_nodemanager_remote_app_log_dir=/app-logs
yarn_nodemanager_log_retain_seconds=2000
yarn_resourcemanager_heapsize=512
yarn_nodemanager_heapsize=512
yarn_scheduler_maximum_allocation_mb=3000
yarn_nodemanager_resource_memory_mb=2000
yarn_nodemanager_resource_cpu_vcores=4
yarn_resourcemanager_zk_path=/yarn-argoidansibletesting
yarn_resourcemanager_cluster_id=argoidansibletesting-testing
yarn_resourcemanager_ha_automatic_failover_zk_base_path=/yarn-prodrtrs-ha-argoidansibletesting
spark_source_url="http://{{ argoid_bigtop_ip }}/argoid_repo/spark/spark-2.3.1-bin-hadoop2.7.tgz"
spark_dir=/opt/spark
spark_history_fs_cleaner_maxAge=48h
spark_history_server_web_port=18080

yarn_resourcemanager_javaOpts="-Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=23701 -javaagent:{{jmx_exporter_java_agent_file}}=23301:{{jmx_exporter_config_file}} "
yarn_nodemanager_javaOpts="-Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=23705 -javaagent:{{jmx_exporter_java_agent_file}}=23305:{{jmx_exporter_config_file}} "

yarn_ha_enabled={{ groups.yarn_resourcemanager | count > 1}}
yarn_timelineserver_web_url={{hostvars[inventory_hostname].groups['yarn_timeline_server'][0]}}:{{yarn_timeline_web_port}}
yarn_log_server_url={{hostvars[inventory_hostname].groups['yarn_mapreduce_jobhistory_server'][0]}}:{{jobhistory_web_port}}
yarn_mapreduce_jobhistory_address={{hostvars[inventory_hostname].groups['yarn_mapreduce_jobhistory_server'][0]}}:{{jobhistory_ipc_port}}
spark_history_server_web_url={{hostvars[inventory_hostname].groups['spark_history_server'][0]}}:{{spark_history_server_web_port}}


[hdfs:children]
hdfs_namenode
hdfs_datanode
hdfs_journalnode

[hdfs_namenode]
172.31.252.13
172.31.252.14

[hdfs_datanode]
172.31.252.13
172.31.252.14

[hdfs_journalnode]
172.31.252.13

[yarn:children]
yarn_resourcemanager
yarn_nodemanager
yarn_timeline_server
yarn_mapreduce_jobhistory_server
spark_history_server
hadoop_clients

[yarn_resourcemanager]
172.31.252.13
172.31.252.14

[yarn_nodemanager]
172.31.252.13
172.31.252.14

[yarn_timeline_server]
172.31.252.13

[yarn_mapreduce_jobhistory_server]
172.31.252.13

[spark_history_server]
172.31.252.13

[hadoop_clients]

[hive:children]
hive_metastore
hive_client

[hive_metastore]
172.31.252.14

[hive_client]
172.31.252.14

[hive:vars]
hive_server2_port=10000
hive_metastore_port=9083
hive_heap_size=512
mysql_connector_source_url=http://{{ argoid_bigtop_ip }}/argoid_repo/mysql/mysql-connector-java-8.0.15.jar
hive_mysql_user=hive
hive_mysql_password=Password@123
hive_mysql_db=metastore
mysql_root_password=Password@123
hive_server2_jmx_port=9008
hive_metastore_jmx_port=9028






[postgres]
192.0.1.12

[postgres:vars]
postgres_mount_data_dir=/data/1/postgres_data
postgres_data_dir=/var/lib/postgresql/data
postgres_password=postgres
postgres_port=5432
postgres_container_name=postgres-12
postgres_docker_image=postgres:12
postgres_exporter_container_name=postgres_exporter
postgres_exporter_docker_image=wrouesnel/postgres_exporter
postgres_exporter_port=9187
postgres_data_source_name=postgresql://postgres:{{postgres_password}}@{{ansible_default_ipv4.address}}:{{postgres_port}}/?sslmode=disable


#Nifi installed in /opt/nifi/nifi-1.13.2/ directory
[nifi]
172.31.252.13

[nifi:vars]
nifi_dir=/opt/nifi
nifi_source_url=https://archive.apache.org/dist/nifi/1.13.2/nifi-1.13.2-bin.tar.gz
force=yes
nifi_port=8080
nifi_user=argoid
nifi_jmx_port=9341
nifi_java_heap_size=612

[node_exporter]
172.31.252.13
172.31.252.14

[node_exporter:vars]
node_exporter_source_url=https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz
node_exporter_dir= /opt/node_exporter
node_exporter_port=9100
force=yes
node_exporter_version=node_exporter-1.2.2.linux-amd64


[kafka]
172.31.252.14

[kafka:vars]
kafka_data_dir=/data/1/kafka
kafka_port=9092
kafka_jmx_port=39321
kafka_heap_size=1G
socket_send_buffer_bytes=1024000
socket_receive_buffer_bytes=1024000
socket_request_max_bytes=10248500
log_retention_hours=168




[mysql]
172.31.252.13

[mysql:vars]
mysql_rpm_source_url=https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
mysql_data_dir=/data/1/mysql/
mysql_root_password=Password@123
mysql_exporter_port=9104
mysql_exporter_source_url=https://github.com/prometheus/mysqld_exporter/releases/download/v0.13.0/mysqld_exporter-0.13.0.linux-amd64.tar.gz
mysql_exporter_version=mysqld_exporter-0.13.0.linux-amd64
mysql_exporter_root_dir=/opt/mysql_exporter

[zeppelin]
172.31.252.13

[zeppelin:vars]
zeppelin_source_url=https://archive.apache.org/dist/zeppelin/{{zeppelin_version}}/{{ zeppelin_version }}-bin-all.tgz
zeppelin_dir=/opt/zeppelin
zeppelin_port=8080
force=yes
zeppelin_jmx_port=40023
zeppelin_version=zeppelin-0.8.1
zeppelin_jvm_heap_size=1024



[presto]
172.31.252.14

[presto:vars]
presto_max_heap_size=12G
query_max_memory=10GB
query_max_memory_per_node=8GB
query_max_total_memory_per_node=8GB
package_upgrade=no
force=yes
presto_user=argoid
presto_properties=templates/node.properties
presto_jmxremote_port=9015
presto_prometheus_port=9483
presto_tar=/tmp/presto-server-0.218.tar.gz
presto_coordinator_ip="{{hostvars[inventory_hostname].groups['presto'][0]}}"
presto_source_url=http://{{argoid_bigtop_ip}}/argoid_repo/presto/presto-server-0.218.tar.gz
presto_data_dir=/var/presto/data/
presto_etc_dir=/opt/presto/etc/
presto_dir=/opt/presto
presto_port=8077
presto_hive_conn="{{hostvars[inventory_hostname].groups['hive_metastore'][0]}}:9083"


[cassandra]
172.31.252.14

[cassandra:vars]
cassandra_port=9042
force=yes
cassandra_jmx_port=33305
cassandra_max_heap_size=2G
cassandra_heap_newsize=200M
cassandra_user=argoid
cassandra_source_url=cassandra.noarch
cassandra_data_dir=/data/1/cassandra
cassandra_cluster=sample


[kairosdb]
172.31.252.14

[kairosdb:vars]
argoid_repo="{{argoid_bigtop_ip}}/argoid_repo"
kairosdb_source_url=http://{{argoid_repo}}/kairosdb/kairosdb-1.2.2-1.rpm
kairosdb_port=8081
package_upgrade=no
force=yes
